{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# through tuning the parameter sof index, we can get different vectorDB retrival performance\n",
    "# we select two basic index as the object, IVF, and HNSW.\n",
    "\n",
    "# we use the dataset\n",
    "# - Glove-25-angular, dimension 25 train set 1,183,514 test set 10,000\n",
    "# download ref: http://ann-benchmarks.com/glove-25-angular.hdf5\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from pymilvus import MilvusClient, DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"\\n=== {:30} ===\\n\"\n",
    "search_latency_fmt = \"search latency = {:.4f}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"./glove-25-angular.hdf5\", \"r\")\n",
    "num_entities, dim = f['train'].shape\n",
    "distance = f.attrs['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default', 'testdb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------  1. Connect to Milvus Server \n",
    "HOST = '10.10.10.247'\n",
    "PORT = 19530\n",
    "DB_NAME = 'testdb'\n",
    "URL=HOST+':'+str(PORT)\n",
    "# if you deployed the standalone milvus, and connect to the database server\n",
    "# if you deployed in your local machine, use \"http://localhost:19530\"\n",
    "client = MilvusClient(\"http://10.10.10.247:19530\")\n",
    "\n",
    "if DB_NAME not in client.list_databases():\n",
    "    client.create_database(DB_NAME)\n",
    "client.using_database(DB_NAME)\n",
    "client.list_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 2. Create a collection with customized schema\n",
    "# we are going to create a collection with 2 fields\n",
    "# +-+------------+------------+------------------+------------------------------+\n",
    "# | | field name | field type | other attributes |       field description      |\n",
    "# +-+------------+------------+------------------+------------------------------+\n",
    "# |1|    \"pk\"    |   VarChar  |  is_primary=True |      \"primary field\"         |\n",
    "# +-+------------+------------+------------------+------------------------------+\n",
    "# |2|\"embeddings\"| FloatVector|     dim=dim     |\"float vector with specific dim\"|\n",
    "# +-+------------+------------+------------------+------------------------------+\n",
    "COLLECTION_NAME = \"glove_25_anugular\"\n",
    "schema = MilvusClient.create_schema(\n",
    "    auto_id = False,\n",
    "    enable_dynamic_field = True,\n",
    ")\n",
    "\n",
    "schema.add_field(field_name = 'pk', datatype=DataType.INT64, is_primary=True, auto_id = False)\n",
    "schema.add_field(field_name = 'embeddings', datatype=DataType.FLOAT_VECTOR, dim=dim)\n",
    "\n",
    "if client.has_collection(COLLECTION_NAME):\n",
    "    client.drop_collection(COLLECTION_NAME)\n",
    "res = client.create_collection(collection_name = COLLECTION_NAME, schema = schema)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 3. Insert data into the collection\n",
    "data = [\n",
    "    {\"pk\":i[0], \"embeddings\":i[1]}\n",
    "    for i in zip(range(num_entities), f['train'][:])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted 100000/1183514, result = 100000\n",
      "inserted 200000/1183514, result = 100000\n",
      "inserted 300000/1183514, result = 100000\n",
      "inserted 400000/1183514, result = 100000\n",
      "inserted 500000/1183514, result = 100000\n",
      "inserted 600000/1183514, result = 100000\n",
      "inserted 700000/1183514, result = 100000\n",
      "inserted 800000/1183514, result = 100000\n",
      "inserted 900000/1183514, result = 100000\n",
      "inserted 1000000/1183514, result = 100000\n",
      "inserted 1100000/1183514, result = 100000\n",
      "inserted 1200000/1183514, result = 83514\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100_000\n",
    "for batch in range(0, num_entities, batch_size):\n",
    "    res = client.insert(collection_name = COLLECTION_NAME, data = data[batch:batch+batch_size])\n",
    "    print(f\"inserted {batch+batch_size}/{num_entities}, result = {res['insert_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 1183514}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flush and check the number of entities\n",
    "client.flush(collection_name=COLLECTION_NAME)\n",
    "client.get_collection_stats(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 4[IVF_FLAT]. Create IVF_FLAT index\n",
    "# in this tutorial, we will deep into the index and tuning the parameters\n",
    "\n",
    "# IVF_FLAT - Inverted File FLAT Index\n",
    "# which aims to improve the search performance of the basic FLAT index \n",
    "# by implementing approximate nearest neighbors (ANNs) algorithm instead of the native KNN (FLAT). \n",
    "# recommend to read this blog: https://zilliz.com/learn/how-to-pick-a-vector-index-in-milvus-visual-guide\n",
    "\n",
    "# IVF-FLAT provides two hyperparameters we can tune:\n",
    "\n",
    "# - nlist: the number of partitions to create using the k-means algorithm. default-128\n",
    "# we determine the nlist when building the IVF-FLAT Index\n",
    "# generally, nlist impacts both indexing time and query performance.\n",
    "# adjuting nlist is relatively complex and expensive\n",
    "\n",
    "# - nprobe: the number of partitions to consider during the search for candidate\n",
    "# we can tune nprobe when executing each query request\n",
    "# generally, given a nlist, nprobe tuning is more intuitive and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index time: 17.5975s\n"
     ]
    }
   ],
   "source": [
    "# first, we fix nlist, tune nprobe to check the query performance (latency and recall)\n",
    "nlist = 1024\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"embeddings\",\n",
    "    metric_type = \"COSINE\",\n",
    "    # related distance metric to angular is CONSINE\n",
    "    index_type = \"IVF_FLAT\",\n",
    "    index_name = \"vector_index\",\n",
    "    params = {\n",
    "        \"nlist\":nlist\n",
    "    }    \n",
    ")\n",
    "start_time = time.time()\n",
    "client.create_index(collection_name = COLLECTION_NAME, \n",
    "                   index_params = index_params,\n",
    "                   sync = True)\n",
    "end_time = time.time()\n",
    "print(f\"create index time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load collection into memory    ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "res = client.get_load_state(collection_name=COLLECTION_NAME)\n",
    "print(fmt.format(\"Load collection into memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_index\n",
    "neighbors_num = f['neighbors'].shape[1]\n",
    "neighbors = f['neighbors'][:]\n",
    "query_embedding = f['test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ----------------- nprobe=1 search -------------------- ===\n",
      "\n",
      "search latency = 3.8174s\n",
      "Mean Average Recall = 0.3681\n",
      "\n",
      "=== ----------------- nprobe=16 search -------------------- ===\n",
      "\n",
      "search latency = 4.2593s\n",
      "Mean Average Recall = 0.8873\n",
      "\n",
      "=== ----------------- nprobe=64 search -------------------- ===\n",
      "\n",
      "search latency = 6.7913s\n",
      "Mean Average Recall = 0.9804\n",
      "\n",
      "=== ----------------- nprobe=256 search -------------------- ===\n",
      "\n",
      "search latency = 13.6901s\n",
      "Mean Average Recall = 0.9994\n",
      "\n",
      "=== ----------------- nprobe=1024 search -------------------- ===\n",
      "\n",
      "search latency = 43.0186s\n",
      "Mean Average Recall = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 4[IVF_FLAT]. Search with different nprobe, check the performance\n",
    "for nprobe in [1,16, 64, 256, 1024]:\n",
    "    start_time = time.time()\n",
    "    res = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=query_embedding,\n",
    "        limit = 100,\n",
    "        search_params={\n",
    "            \"params\" : {\"nprobe\":nprobe}\n",
    "        }\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(fmt.format(f\"----------------- nprobe={nprobe} search --------------------\"))\n",
    "    print(search_latency_fmt.format(end_time-start_time))\n",
    "    \n",
    "    # calculate the Mean Average Recall.\n",
    "    # Recall@K = (# of true positive in top K) / (# of true positive)\n",
    "    # MAR (Mean Average Recall) = 1/C * sum(Recall@K). C is the number of queries\n",
    "    mar_ = []\n",
    "    for i, candidate_res in enumerate(res):\n",
    "        y = neighbors[i]\n",
    "        y_ = [j['id'] for j in candidate_res]\n",
    "        y, y_ = set(y), set(y_)\n",
    "        mar_.append(1.0 * len(y & y_) / len(y))\n",
    "    mar = np.mean(mar_)\n",
    "    print(f\"Mean Average Recall = {mar:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the result, we can easily find that\n",
    "# with the increase of nprobe, the search latency increase while the recall degrade\n",
    "# nprobe represents the number of partitions to consider during the search candidate\n",
    "# the value is in the range of [1, nlist].\n",
    "# When it is 1, only one partion is considered, which is the fastest but with loss of recall\n",
    "# When it is nlist, all partition is considered, equal to the FLAT index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index and change nlist to 256 \n",
    "client.release_collection(\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "client.drop_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=\"vector_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index time: 3.5281s\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 4[IVF_FLAT]. Create IVF_FLAG index with nlist=256\n",
    "nlist = 256\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"embeddings\",\n",
    "    metric_type = \"COSINE\",\n",
    "    # related distance metric to angular is CONSINE\n",
    "    index_type = \"IVF_FLAT\",\n",
    "    index_name = \"vector_index\",\n",
    "    params = {\n",
    "        \"nlist\":nlist\n",
    "    }    \n",
    ")\n",
    "start_time = time.time()\n",
    "client.create_index(collection_name = COLLECTION_NAME, \n",
    "                   index_params = index_params,\n",
    "                   sync = True)\n",
    "end_time = time.time()\n",
    "print(f\"create index time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load collection into memory    ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decrease the nlist, we spend less time on indexing building\n",
    "# load it into memory\n",
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "res = client.get_load_state(collection_name=COLLECTION_NAME)\n",
    "print(fmt.format(\"Load collection into memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ----------------- nprobe=1 search -------------------- ===\n",
      "\n",
      "search latency = 3.2711s\n",
      "Mean Average Recall = 0.4697\n",
      "\n",
      "=== ----------------- nprobe=16 search -------------------- ===\n",
      "\n",
      "search latency = 5.8951s\n",
      "Mean Average Recall = 0.9495\n",
      "\n",
      "=== ----------------- nprobe=64 search -------------------- ===\n",
      "\n",
      "search latency = 12.3161s\n",
      "Mean Average Recall = 0.9971\n",
      "\n",
      "=== ----------------- nprobe=256 search -------------------- ===\n",
      "\n",
      "search latency = 38.0888s\n",
      "Mean Average Recall = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 4[IVF_FLAT]. Search with different nprobe, check the performance\n",
    "for nprobe in [1, 16, 64, 256]:\n",
    "    start_time = time.time()\n",
    "    res = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=query_embedding,\n",
    "        limit = 100,\n",
    "        search_params={\n",
    "            \"params\" : {\"nprobe\":nprobe}\n",
    "        }\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(fmt.format(f\"----------------- nprobe={nprobe} search --------------------\"))\n",
    "    print(search_latency_fmt.format(end_time-start_time))\n",
    "    \n",
    "    # calculate the Mean Average Recall.\n",
    "    # Recall@K = (# of true positive in top K) / (# of true positive)\n",
    "    # MAR (Mean Average Recall) = 1/C * sum(Recall@K). C is the number of queries\n",
    "    mar_ = []\n",
    "    for i, candidate_res in enumerate(res):\n",
    "        y = neighbors[i]\n",
    "        y_ = [j['id'] for j in candidate_res]\n",
    "        y, y_ = set(y), set(y_)\n",
    "        mar_.append(1.0 * len(y & y_) / len(y))\n",
    "    mar = np.mean(mar_)\n",
    "    print(f\"Mean Average Recall = {mar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when nlist decrease, given the same nprobe, more candidates cause the mar increase.\n",
    "# basically, nlist is a probe to control the granularity of the search space.\n",
    "# also increasing nlist makes the index building process slow\n",
    "# generally, there are several situations to tune nlist:\n",
    "# - the dataset is large, the nlist should be large\n",
    "# - low recall during search, the nprobe is fixed, decrease nlist\n",
    "# - the search latency is high, the nprobe is fixed, increase nlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index \n",
    "client.release_collection(\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "client.drop_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=\"vector_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- 5.[HNSW]. Create HNSW index\n",
    "\n",
    "# HNSW: Hierarchical Navigable Small World\n",
    "# algorithm detail refer to paper https://arxiv.org/pdf/1603.09320\n",
    "\n",
    "# HNSW provides three hyperparameters we can tune:\n",
    "\n",
    "# When building index:\n",
    "# - M: the maximum number of connections for each node in the graph. \n",
    "# Higher M makes the graph more connected, which increase memory suage and indexing building time.\n",
    "# but with higher search quality.\n",
    "\n",
    "# - efConstruction: the size of the dynamic cnadidate list which controls index seach speed/build speed tradeoff.\n",
    "# Higher efConstruction makes the index building slower but with higher search quality.\n",
    "\n",
    "# When searching:\n",
    "# - ef: the size of the dynamic candidate list during search.\n",
    "# Higher ef makes the search slower and memory usage higher but with higher search quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index time: 89.4777s\n"
     ]
    }
   ],
   "source": [
    "M = 32\n",
    "ef_construct = 500\n",
    "\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"embeddings\",\n",
    "    metric_type = \"COSINE\",\n",
    "    # related distance metric to angular is CONSINE\n",
    "    index_type = \"HNSW\",\n",
    "    index_name = \"vector_index\",\n",
    "    params = {\n",
    "        \"M\":M,\n",
    "        \"efConstruction\":ef_construct\n",
    "    }    \n",
    ")\n",
    "start_time = time.time()\n",
    "client.create_index(collection_name = COLLECTION_NAME, \n",
    "                   index_params = index_params,\n",
    "                   sync = True)\n",
    "end_time = time.time()\n",
    "print(f\"create index time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load collection into memory    ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "res = client.get_load_state(collection_name=COLLECTION_NAME)\n",
    "print(fmt.format(\"Load collection into memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ----------------- ef=100 search -------------------- ===\n",
      "\n",
      "search latency = 4.0822s\n",
      "Mean Average Recall = 0.9758\n",
      "\n",
      "=== ----------------- ef=200 search -------------------- ===\n",
      "\n",
      "search latency = 4.2695s\n",
      "Mean Average Recall = 0.9949\n",
      "\n",
      "=== ----------------- ef=400 search -------------------- ===\n",
      "\n",
      "search latency = 5.1274s\n",
      "Mean Average Recall = 0.9993\n",
      "\n",
      "=== ----------------- ef=800 search -------------------- ===\n",
      "\n",
      "search latency = 7.0809s\n",
      "Mean Average Recall = 0.9999\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 5.[HNSW]. Search with different ef, check the performance\n",
    "for ef in [100, 200, 400, 800]:\n",
    "    start_time = time.time()\n",
    "    res = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=query_embedding,\n",
    "        limit = 100,\n",
    "        search_params={\n",
    "            \"params\" : {\"ef\":ef}\n",
    "        }\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(fmt.format(f\"----------------- ef={ef} search --------------------\"))\n",
    "    print(search_latency_fmt.format(end_time-start_time))\n",
    "    \n",
    "    # calculate the Mean Average Recall.\n",
    "    # Recall@K = (# of true positive in top K) / (# of true positive)\n",
    "    # MAR (Mean Average Recall) = 1/C * sum(Recall@K). C is the number of queries\n",
    "    mar_ = []\n",
    "    for i, candidate_res in enumerate(res):\n",
    "        y = neighbors[i]\n",
    "        y_ = [j['id'] for j in candidate_res]\n",
    "        y, y_ = set(y), set(y_)\n",
    "        mar_.append(1.0 * len(y & y_) / len(y))\n",
    "    mar = np.mean(mar_)\n",
    "    print(f\"Mean Average Recall = {mar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the result, we can easily find that\n",
    "# with the increase of ef, the search latency increase while the recall degrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index \n",
    "client.release_collection(\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "client.drop_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=\"vector_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index time: 39.2173s\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 5.[HNSW]. Create HNSW index - Decrease M\n",
    "M = 8\n",
    "ef_construct = 500\n",
    "\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"embeddings\",\n",
    "    metric_type = \"COSINE\",\n",
    "    # related distance metric to angular is CONSINE\n",
    "    index_type = \"HNSW\",\n",
    "    index_name = \"vector_index\",\n",
    "    params = {\n",
    "        \"M\":M,\n",
    "        \"efConstruction\":ef_construct\n",
    "    }    \n",
    ")\n",
    "start_time = time.time()\n",
    "client.create_index(collection_name = COLLECTION_NAME, \n",
    "                   index_params = index_params,\n",
    "                   sync = True)\n",
    "end_time = time.time()\n",
    "print(f\"create index time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index building time decrease with the decrease of M.\n",
    "# index building time 89s -> 39s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load collection into memory    ===\n",
      "\n",
      "\n",
      "=== ----------------- ef=100 search -------------------- ===\n",
      "\n",
      "search latency = 3.1490s\n",
      "Mean Average Recall = 0.8430\n",
      "\n",
      "=== ----------------- ef=200 search -------------------- ===\n",
      "\n",
      "search latency = 4.0087s\n",
      "Mean Average Recall = 0.9208\n",
      "\n",
      "=== ----------------- ef=400 search -------------------- ===\n",
      "\n",
      "search latency = 4.1213s\n",
      "Mean Average Recall = 0.9674\n",
      "\n",
      "=== ----------------- ef=800 search -------------------- ===\n",
      "\n",
      "search latency = 5.3935s\n",
      "Mean Average Recall = 0.9891\n"
     ]
    }
   ],
   "source": [
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "res = client.get_load_state(collection_name=COLLECTION_NAME)\n",
    "print(fmt.format(\"Load collection into memory\"))\n",
    "\n",
    "# ------------------- 5.[HNSW]. Search with different ef, check the performance\n",
    "for ef in [100, 200, 400, 800]:\n",
    "    start_time = time.time()\n",
    "    res = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=query_embedding,\n",
    "        limit = 100,\n",
    "        search_params={\n",
    "            \"params\" : {\"ef\":ef}\n",
    "        }\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(fmt.format(f\"----------------- ef={ef} search --------------------\"))\n",
    "    print(search_latency_fmt.format(end_time-start_time))\n",
    "    \n",
    "    # calculate the Mean Average Recall.\n",
    "    # Recall@K = (# of true positive in top K) / (# of true positive)\n",
    "    # MAR (Mean Average Recall) = 1/C * sum(Recall@K). C is the number of queries\n",
    "    mar_ = []\n",
    "    for i, candidate_res in enumerate(res):\n",
    "        y = neighbors[i]\n",
    "        y_ = [j['id'] for j in candidate_res]\n",
    "        y, y_ = set(y), set(y_)\n",
    "        mar_.append(1.0 * len(y & y_) / len(y))\n",
    "    mar = np.mean(mar_)\n",
    "    print(f\"Mean Average Recall = {mar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the ef and efConstruction, \n",
    "# decrease M makes the search quality decrease but speed up the search process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index \n",
    "client.release_collection(\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "client.drop_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=\"vector_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index time: 22.1257s\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 5.[HNSW]. Create HNSW index - Decrease efConstruction\n",
    "M = 32\n",
    "ef_construct = 100\n",
    "\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"embeddings\",\n",
    "    metric_type = \"COSINE\",\n",
    "    # related distance metric to angular is CONSINE\n",
    "    index_type = \"HNSW\",\n",
    "    index_name = \"vector_index\",\n",
    "    params = {\n",
    "        \"M\":M,\n",
    "        \"efConstruction\":ef_construct\n",
    "    }    \n",
    ")\n",
    "start_time = time.time()\n",
    "client.create_index(collection_name = COLLECTION_NAME, \n",
    "                   index_params = index_params,\n",
    "                   sync = True)\n",
    "end_time = time.time()\n",
    "print(f\"create index time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index building time decrease with the decrease of efConstruction.\n",
    "# index building time 89s -> 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Load collection into memory    ===\n",
      "\n",
      "\n",
      "=== ----------------- ef=100 search -------------------- ===\n",
      "\n",
      "search latency = 3.5012s\n",
      "Mean Average Recall = 0.9574\n",
      "\n",
      "=== ----------------- ef=200 search -------------------- ===\n",
      "\n",
      "search latency = 4.5053s\n",
      "Mean Average Recall = 0.9862\n",
      "\n",
      "=== ----------------- ef=400 search -------------------- ===\n",
      "\n",
      "search latency = 4.4190s\n",
      "Mean Average Recall = 0.9963\n",
      "\n",
      "=== ----------------- ef=800 search -------------------- ===\n",
      "\n",
      "search latency = 6.8445s\n",
      "Mean Average Recall = 0.9993\n"
     ]
    }
   ],
   "source": [
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "res = client.get_load_state(collection_name=COLLECTION_NAME)\n",
    "print(fmt.format(\"Load collection into memory\"))\n",
    "\n",
    "# ------------------- 5.[HNSW]. Search with different ef, check the performance\n",
    "for ef in [100, 200, 400, 800]:\n",
    "    start_time = time.time()\n",
    "    res = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=query_embedding,\n",
    "        limit = 100,\n",
    "        search_params={\n",
    "            \"params\" : {\"ef\":ef}\n",
    "        }\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(fmt.format(f\"----------------- ef={ef} search --------------------\"))\n",
    "    print(search_latency_fmt.format(end_time-start_time))\n",
    "    \n",
    "    # calculate the Mean Average Recall.\n",
    "    # Recall@K = (# of true positive in top K) / (# of true positive)\n",
    "    # MAR (Mean Average Recall) = 1/C * sum(Recall@K). C is the number of queries\n",
    "    mar_ = []\n",
    "    for i, candidate_res in enumerate(res):\n",
    "        y = neighbors[i]\n",
    "        y_ = [j['id'] for j in candidate_res]\n",
    "        y, y_ = set(y), set(y_)\n",
    "        mar_.append(1.0 * len(y & y_) / len(y))\n",
    "    mar = np.mean(mar_)\n",
    "    print(f\"Mean Average Recall = {mar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the ef and M, \n",
    "# decrease efConstruction makes the search quality decrease but speed up the search process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
