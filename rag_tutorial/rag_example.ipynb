{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect news meta data,\n",
    "file_path = './news1.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    news = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'company',\n",
       "  'datetime': 1731968631,\n",
       "  'headline': 'Mag 7 vs. S&P 493: Is earnings growth beginning to slow?',\n",
       "  'id': 131461305,\n",
       "  'image': 'https://s.yimg.com/ny/api/res/1.2/eKS.TjTPOUaiMZHSvZav1w--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzQ-/https://s.yimg.com/os/creatr-uploaded-images/2024-10/8ef63850-a5fb-11ef-bfbf-7c0ad8de5650',\n",
       "  'related': 'AAPL',\n",
       "  'source': 'Yahoo',\n",
       "  'summary': 'Magnificent Seven stocks — which is comprised of Alphabet (GOOGL, GOOG), Amazon (AMZN), Apple (AAPL), Meta Platforms (META), Microsoft (MSFT), Nvidia (NVDA), and Tesla (TSLA) — are experiencing a deceleration in growth across their earnings. Nvidia is the next and final member of the group to report earnings this Wednesday, November 20. Yahoo Finance acnhor Julie Hyman joins Asking for a Trend to compare the Mag 7\\'s earnings growth compared to that of the rest of the S&P 500 (^GSPC), referring back to Solidarity Capital CEO Jeff McClean\\'s comments to Yahoo Finance: \"I think there\\'s going to continue to be broadening with the rest of the S&P 493.\" To watch more expert insights and analysis on the latest market action, check out more Asking for a Trend\\xa0here. This post was written by Luke Carberry Mogan.',\n",
       "  'url': 'https://finnhub.io/api/news?id=430f9b307b24d9a2bb9cca9f70b479d684de50e3833e1e8f0bffb5817b8a590a'},\n",
       " {'category': 'company',\n",
       "  'datetime': 1731957610,\n",
       "  'headline': 'Apple Evaluates Branded TV as Smart Home Focus Grows',\n",
       "  'id': 131462767,\n",
       "  'image': 'https://media.zenfs.com/en/us.finance.gurufocus/f6d5f9d51b104961cf24aa8d5b100889',\n",
       "  'related': 'AAPL',\n",
       "  'source': 'Yahoo',\n",
       "  'summary': 'Apple is reportedly reevaluating plans to release a branded television',\n",
       "  'url': 'https://finnhub.io/api/news?id=6907e58db6dfd3d62620847b09f924818b5d0db563820c2e423f03902bf182ac'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the schema of json file\n",
    "news[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 21.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# collect all news content from html files with beautifulsoup\n",
    "contents = {}\n",
    "for new in tqdm(news):\n",
    "    filename = str(new['id'])+'.html'\n",
    "    filepath = os.path.join('./news1', filename)\n",
    "    with open(filepath, 'r') as f:\n",
    "        html = f.read()\n",
    "        content = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    contents[new['id']] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1494.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# parse the content and construct the new's text information\n",
    "def parse_text_in_bs(content: BeautifulSoup):\n",
    "    paragraphs = []\n",
    "    for ptext in content.find_all('p'):\n",
    "        if not ptext.text:\n",
    "            continue\n",
    "        paragraphs.append(ptext.text.strip())\n",
    "    return  '\\n'.join(paragraphs)\n",
    "\n",
    "# save it based on id as key\n",
    "pages = {}\n",
    "for key,content in tqdm(contents.items()):\n",
    "    pages[key] = parse_text_in_bs(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Retrieval-Augmented-Generation (RAG) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...Neil Armstrong. He stepped onto the lunar surface on July 20, 1969, as part of the Apollo 11 mission. His famous words upon setting foot on the moon were: \"That\\'s one small step for man, one giant leap for mankind.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before this, install the ollama\n",
    "# for linux user: curl -fsSL https://ollama.com/install.sh | sh\n",
    "# or using Docker image to run llama.\n",
    "# refer to https://github.com/ollama/ollama, find the model which your local computer can hold.\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# interact with the LLM to verify service is running.\n",
    "llm.invoke(\"The first man on the moon was ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/lingze/anaconda3/envs/cs4221/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained embedding model\n",
    "# which is used to encode text to embedding vectors.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# this model: https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "# refer to huggingface hub for more models\n",
    "\n",
    "\n",
    "\n",
    "# there we need a vectordb to store the embedding vector and support the efficient similarity search.\n",
    "# Considering the size of the dataset is small, we just use the in-memory vectorstore\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Documentation based on our collected news data\n",
    "docs = []\n",
    "for new in news:\n",
    "    page = pages[new['id']]\n",
    "    doc = Document(page_content=page, metadata=new)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case our loaded document is too long to fit into the context window of the LLM, we need to split it into smaller chunks.\n",
    "# Even for those LLM or embedding LM that cold fit the full document in their context window, models still struggle to find information in very long inputs.\n",
    "\n",
    "# Split the documents into chunks for embedding and vector storage,\n",
    "# this could help us retrieve only the most relevant chunks when we search in certain query.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these chunks into vectordb for later similarity search.\n",
    "# maybe takes several minutes to encode all document and save it into vectordb\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/lingze/anaconda3/envs/cs4221/lib/python3.9/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the prompt is a template for augmentation step in the RAG pipeline,\n",
    "# it contains two input fields: \"question\" and \"context\"\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "\n",
    "# these are two predefined interface in langchain rag framework.\n",
    "\n",
    "# retrieve: just invoke the vectordb's similarity search to retrieve the most relevant documents based on the question.\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# generate: invoke the LLM to generate the answer based on the retrieved documents.\n",
    "# the retrieved documents are joined together as the context for the LLM.\n",
    "# the question is also passed to the LLM as the query.\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a related article and query based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'company',\n",
      " 'datetime': 1731926825,\n",
      " 'headline': 'Tata Electronics to acquire stake in Pegatron iPhone plant',\n",
      " 'id': 131462772,\n",
      " 'image': 'https://www.verdict.co.uk/wp-content/uploads/2024/11/12-shutterstock_2374133657.jpg',\n",
      " 'related': 'AAPL',\n",
      " 'source': 'Yahoo',\n",
      " 'summary': 'The acquisition will result in a joint venture, in which Tata '\n",
      "            'will own 60% and Pegatron will have 40% interest.',\n",
      " 'url': 'https://finnhub.io/api/news?id=9afbb03728fdfe6c793146a49d8d665f560b083218fc23e503bed29a4b11d0ad'}\n",
      "\n",
      "\n",
      "\n",
      "('The acquisition will result in a joint venture, in which Tata will own 60% '\n",
      " 'and Pegatron will have 40% interest.\\n'\n",
      " 'Tata Electronics has agreed to purchase majority stake in the iPhone '\n",
      " 'manufacturing facility in India from Taiwanese firm Pegatron, reports '\n",
      " 'Reuters.\\n'\n",
      " 'The move will result in a joint venture, in which Tata will own 60% and '\n",
      " 'manage daily operations. Pegatron will have a 40% stake, and provide '\n",
      " 'technical support, two sources said.\\n'\n",
      " 'The gold standard of business intelligence.\\n'\n",
      " 'Find out more\\n'\n",
      " 'The deal marks Pegatron’s latest scale-back of its Apple partnership.\\n'\n",
      " 'In April 2024, Reuters reported that Pegatron was in advanced talks to sell '\n",
      " 'its only iPhone plant in India to Tata, marking its latest scale back of its '\n",
      " 'partnership with Apple.\\n'\n",
      " 'Apple is diversifying its supply chain beyond China due to geopolitical '\n",
      " 'tensions between Beijing and Washington.\\n'\n",
      " 'For Tata, acquiring the Chennai Pegatron plant will enhance its iPhone '\n",
      " 'manufacturing capabilities.\\n'\n",
      " 'Access the most comprehensive Company Profiles\\n'\n",
      " '            on the market, powered by GlobalData. Save hours of research. '\n",
      " 'Gain competitive edge.\\n'\n",
      " 'Your download email will arrive shortly\\n'\n",
      " 'We are confident about the\\n'\n",
      " '                        unique\\n'\n",
      " '                        quality of our Company Profiles. However, we want '\n",
      " 'you to make the most\\n'\n",
      " '                        beneficial\\n'\n",
      " '                        decision for your business, so we offer a free '\n",
      " 'sample that you can download by\\n'\n",
      " '                        submitting the below form\\n'\n",
      " 'The companies plan to seek approval from the Competition Commission of India '\n",
      " 'soon.\\n'\n",
      " 'Tata already operates an iPhone assembly plant in Karnataka that was '\n",
      " 'acquired from Taiwan’s Wistron in 2023.\\n'\n",
      " 'Tata is also building another in Hosur, Tamil Nadu, where it also has an '\n",
      " 'iPhone component plant.\\n'\n",
      " 'The Tata-Pegatron plant has around 10,000 employees. It has production '\n",
      " 'capacity of five million iPhones annually and marks Tata’s third iPhone '\n",
      " 'factory in India.\\n'\n",
      " 'Earlier in November 2024, the Economic Times reported that Apple established '\n",
      " 'its first wholly owned subsidiary in India, Apple Operations India, to '\n",
      " 'expand its R&D capabilities in the region.\\n'\n",
      " 'As per the regulatory filing, Apple Operations India will focus on procuring '\n",
      " 'engineering equipment, leasing facilities, employing engineers for hardware '\n",
      " 'development and providing failure analysis services to group companies.\\n'\n",
      " 'The gold standard of business intelligence.\\n'\n",
      " 'Find out more\\n'\n",
      " 'Give your business an edge with our leading industry insights.\\n'\n",
      " 'Give your business an edge with our leading industry insights.\\n'\n",
      " '\\n'\n",
      " 'Thematic Take (monthly)\\n'\n",
      " 'I consent to Verdict Media Limited collecting my details provided via this '\n",
      " 'form in accordance with  Privacy Policy\\n'\n",
      " 'View all newsletters from across the GlobalData Media network.\\n'\n",
      " 'Decrypting the latest technology news\\n'\n",
      " 'Powered by\\n'\n",
      " '© Verdict Media Limited 2024')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(news[10])\n",
    "print('\\n\\n')\n",
    "pprint.pprint(pages[news[10]['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I don't know the current status or performance of Tata Electronics \"\n",
      " 'specifically beyond the information provided about their iPhone '\n",
      " 'manufacturing plans and acquisition of the Chennai Pegatron plant. The '\n",
      " 'company is expanding its iPhone manufacturing capabilities and has been '\n",
      " 'increasing its presence in the Indian market. Tata operates an existing '\n",
      " \"iPhone assembly plant in Karnataka that was acquired from Taiwan's Wistron \"\n",
      " 'in 2023.')\n"
     ]
    }
   ],
   "source": [
    "# check the answer\n",
    "response = graph.invoke({\"question\": \"How's going with Tata Electronics\"})\n",
    "pprint.pprint(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
